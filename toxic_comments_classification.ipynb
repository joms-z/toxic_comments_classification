{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification\n",
    "\n",
    "This notebook explores a few deep learning methods to detect different types of toxicity like threats, obscenity, insults, and identity-based hate in online comments. The models are trained and tested on a dataset of comments from Wikipedia's talk page edits.\n",
    "\n",
    "This is a recently concluded Kaggle competition. More details can be found [here](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Explored:\n",
    "\n",
    "Since the focus is on deep learning, the baseline model is a nerual net with one hidden layer with 128 units that takes as input a count vector based on a vocabulary size of 15000. The models explored thereafter are:\n",
    "1. A neural net that learns an embedding layer\n",
    "2. A neural net that uses transfer learning by using the GloVe model for initialization of weights of embedding layer\n",
    "3. A recurrent neural net that uses the GloVe model as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import _pickle as pkl\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Flatten, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "from keras.models import load_model\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id                                       comment_text  \\\n",
      "132098  c2e4984fc60bdcf5  right i cant email you for some weird reason i...   \n",
      "34027   5ac9bd5e6591d3a0  I don't quite get edit summary. Can you please...   \n",
      "37124   6318b61ce38def8a  Battleground spirit ; removal of source materi...   \n",
      "80033   d620e563f3ada671  \"\\n\\nTalk Page Message\\nNo, I was removing Dre...   \n",
      "152635  904973fde1b8394c  If you visited Middlesbrough especially the ri...   \n",
      "\n",
      "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
      "132098      0             0        0       0       0              0  \n",
      "34027       0             0        0       0       0              0  \n",
      "37124       0             0        0       0       0              0  \n",
      "80033       0             0        0       0       0              0  \n",
      "152635      0             0        0       0       0              0  \n"
     ]
    }
   ],
   "source": [
    "# set seed for reproducibility\n",
    "seed = 9\n",
    "np.random.seed(seed)\n",
    "\n",
    "# load the training data\n",
    "data = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# check a sample of the training data\n",
    "print (data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               False\n",
      "comment_text     False\n",
      "toxic            False\n",
      "severe_toxic     False\n",
      "obscene          False\n",
      "threat           False\n",
      "insult           False\n",
      "identity_hate    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# check if there are any null values in the training data\n",
    "print (data.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9865, 9)\n"
     ]
    }
   ],
   "source": [
    "dependent_vars = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "data['sum_dvs'] = data[dependent_vars].sum(axis=1)\n",
    "# print number of data points that have more than one label\n",
    "print (data.loc[data['sum_dvs'] > 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, there are 9865 rows with data['sum_dvs'] > 1, we need to treat this problem as a binary classification for all 6 of the labels. i.e. each comment can have more than 1 label - a multi-label mlti-class problem. Hence, we'll be using binary_crossentropy as loss function for the optimizer and a sigmoid activation function(instead of softmax) for the output layer. \n",
    "\n",
    "There are many spelling errors that can be corrected depending on the models used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: (16225, 9)\n",
      "toxic: (15294, 9)\n",
      "severe_toxic: (1595, 9)\n",
      "obscene: (8449, 9)\n",
      "threat: (478, 9)\n",
      "insult: (7877, 9)\n",
      "identity_hate: (1405, 9)\n"
     ]
    }
   ],
   "source": [
    "def display_label_distribution(data):\n",
    "    # find data points that have atleast one label\n",
    "    print ('total:', data.loc[data['sum_dvs'] > 0].shape)\n",
    "\n",
    "    # find how the labels are distributed\n",
    "    for var in dependent_vars:\n",
    "        print (var + ': ' + str(data.loc[data[var] == 1].shape))\n",
    "\n",
    "display_label_distribution(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above indicate that there is a label imbalance in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a vocabulary size\n",
    "max_features = 15000\n",
    "\n",
    "# choose a validation and test split\n",
    "validation_split = 0.1\n",
    "test_split = 0.2\n",
    "\n",
    "#shuffle the dataset\n",
    "data = data.reindex(np.random.permutation(data.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>sum_dvs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35418</th>\n",
       "      <td>5e983bd8ba291ed5</td>\n",
       "      <td>took care one. pinged park, feeding duckies; s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9382</th>\n",
       "      <td>18e505d8aa1fcab0</td>\n",
       "      <td>wrong fag</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>07ff0744ebbf7c82</td>\n",
       "      <td>want ongoing, respond comments made. said newb...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41095</th>\n",
       "      <td>6da6f59a4cc1a4fb</td>\n",
       "      <td>knowledge, wikipedia does policy newspaper art...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41604</th>\n",
       "      <td>6ef66dd18cb089d3</td>\n",
       "      <td>none. massive abuse blocking system, huge over...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                       comment_text  \\\n",
       "35418  5e983bd8ba291ed5  took care one. pinged park, feeding duckies; s...   \n",
       "9382   18e505d8aa1fcab0                                          wrong fag   \n",
       "2959   07ff0744ebbf7c82  want ongoing, respond comments made. said newb...   \n",
       "41095  6da6f59a4cc1a4fb  knowledge, wikipedia does policy newspaper art...   \n",
       "41604  6ef66dd18cb089d3  none. massive abuse blocking system, huge over...   \n",
       "\n",
       "       toxic  severe_toxic  obscene  threat  insult  identity_hate  sum_dvs  \n",
       "35418      0             0        0       0       0              0        0  \n",
       "9382       1             0        0       0       0              0        1  \n",
       "2959       0             0        0       0       0              0        0  \n",
       "41095      0             0        0       0       0              0        0  \n",
       "41604      0             0        0       0       0              0        0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the comments by removing stopwords\n",
    "def clean_comment_text(comment):\n",
    "    stop_words = text.ENGLISH_STOP_WORDS\n",
    "    word_list = []\n",
    "    for word in comment.lower().split():\n",
    "        word = word.replace('!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~0123456789', '')\n",
    "        if (word not in stop_words and len(word) > 1):\n",
    "            word_list.append(word)\n",
    "    cleaned_comment = ' '.join(word_list)\n",
    "    return cleaned_comment\n",
    "\n",
    "data['comment_text'] = data['comment_text'].apply(clean_comment_text)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "total: (11614, 9)\n",
      "toxic: (10947, 9)\n",
      "severe_toxic: (1131, 9)\n",
      "obscene: (6063, 9)\n",
      "threat: (346, 9)\n",
      "insult: (5612, 9)\n",
      "identity_hate: (1027, 9)\n",
      "\n",
      "VALIDATION\n",
      "total: (1309, 9)\n",
      "toxic: (1230, 9)\n",
      "severe_toxic: (104, 9)\n",
      "obscene: (679, 9)\n",
      "threat: (40, 9)\n",
      "insult: (658, 9)\n",
      "identity_hate: (109, 9)\n",
      "\n",
      "TEST\n",
      "total: (3302, 9)\n",
      "toxic: (3117, 9)\n",
      "severe_toxic: (360, 9)\n",
      "obscene: (1707, 9)\n",
      "threat: (92, 9)\n",
      "insult: (1607, 9)\n",
      "identity_hate: (269, 9)\n"
     ]
    }
   ],
   "source": [
    "def split_df(data, split):\n",
    "    size = data.shape[0]\n",
    "    test_size = math.ceil(size * split)\n",
    "\n",
    "    train = data.head(size - test_size)\n",
    "    test = data.tail(test_size)\n",
    "    return train, test\n",
    "\n",
    "# split the data into training, test, and validation sets\n",
    "train, test = split_df(data, test_split)\n",
    "train, validation = split_df(train, validation_split)\n",
    "\n",
    "y_train = train[dependent_vars].values\n",
    "y_validation = validation[dependent_vars].values\n",
    "y_test = test[dependent_vars].values\n",
    "\n",
    "# make sure that all datasets have all the labels\n",
    "print (\"TRAIN\")\n",
    "display_label_distribution(train)\n",
    "print (\"\\nVALIDATION\")\n",
    "display_label_distribution(validation)\n",
    "print (\"\\nTEST\")\n",
    "display_label_distribution(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Tokenizer on only the train data. The vocabulary (max_features) we need to learn should be based only on the \n",
    "# training data. This is so that we can emulate the validation loss as close as possible to that of the test data \n",
    "# where there could be words that we haven't encountered before.\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~0123456789')\n",
    "tokenizer.fit_on_texts(list(train['comment_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Number of unique words: \", len(tokenizer.word_index))\n",
    "\n",
    "# check if the selected vocabulary is reliable\n",
    "count = 0\n",
    "for i, word in tokenizer.word_index.items():\n",
    "    count += 1\n",
    "    print (i, word)\n",
    "    if count > 20000:\n",
    "        break\n",
    "    if count % 10000 == 0:\n",
    "        print (\"########################################################################################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look at the vocabulary reveals that the top 15000 words should likely do a decent job since it contains most hate words and profanity. Considering the model size and training time, we continue with a vocabulary size of 15000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Set 1 - Count Vectors\n",
    "\n",
    "These features are used to train the neural net (Model 1) that accepts count vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a feature set based on counts - a vector of size = vocabulary size\n",
    "x_train = tokenizer.texts_to_matrix(train['comment_text'], mode='count')\n",
    "x_validation = tokenizer.texts_to_matrix(validation['comment_text'], mode='count')\n",
    "x_test = tokenizer.texts_to_matrix(test['comment_text'], mode='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Set 2 - Integer Sequences\n",
    "\n",
    "These features are used to train the models (Models 1, 2, and 3) that accept integer sequences where each integer corresponds\n",
    "to a unique word in our vocabulary. Each comment is therefore represented by a sequence of integers of the words that are in \n",
    "the comment and the vocabulary in the same order. Every comment is then padded or stripped to a fixed length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a feature set based on sequences - sequence of integers for each comment\n",
    "x_train_sequences = tokenizer.texts_to_sequences(train['comment_text'])\n",
    "x_validation_sequences = tokenizer.texts_to_sequences(validation['comment_text'])\n",
    "x_test_sequences = tokenizer.texts_to_sequences(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2387ec72cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# analyze the comments length in x_train_sequences to decide on a max comment length\n",
    "comments_lengths = [len(comment) for comment in x_train_sequences]\n",
    "plt.hist(comments_lengths, bins=np.arange(0, 450, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the the histogram above reveals that selecting a comment length of 100 should be a safe bet, \n",
    "since it covers most of the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "\n",
    "# pad the training, validation, and test sets to have a maximum length of 100\n",
    "x_train_sequences_padded = pad_sequences(x_train_sequences, maxlen=max_len)\n",
    "x_validation_sequences_padded = pad_sequences(x_validation_sequences, maxlen=max_len)\n",
    "x_test_sequences_padded = pad_sequences(x_test_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric\n",
    "\n",
    "The evaluation metric used in [kaggle](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge#evaluation) is the average of the individual AUROCs of each predicted column. Given that this is a multi-label, multi-class problem with class imbalance, this metric makes sense too. So, we'll use the same metric during model training and evalution.\n",
    "\n",
    "Note: The AUROC score indicates the probability that a uniformly drawn postive random sample is ranked higher than a uniformly drawn negative random sample. This score is agnostic of the threshold used for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUROC(Callback):\n",
    "    def __init__(self, validation_data=()):\n",
    "        super(Callback, self).__init__()\n",
    "        self.x, self.y = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        # Calculate roc_auc_score. For multi-label, this function averages over the labels\n",
    "        score = roc_auc_score(self.y, y_pred)\n",
    "        print(\"val AUROC: %.6f\" % (score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 (Baseline) - NN Using Count Vectors as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/10\n",
      "127656/127656 [==============================] - 276s 2ms/step - loss: 0.1651 - acc: 0.9681 - val_loss: 0.0878 - val_acc: 0.9759\n",
      "val AUROC: 0.894829\n",
      "Epoch 2/10\n",
      "127656/127656 [==============================] - 232s 2ms/step - loss: 0.0690 - acc: 0.9794 - val_loss: 0.0744 - val_acc: 0.9784\n",
      "val AUROC: 0.932605\n",
      "Epoch 3/10\n",
      "127656/127656 [==============================] - 208s 2ms/step - loss: 0.0530 - acc: 0.9832 - val_loss: 0.0709 - val_acc: 0.9791\n",
      "val AUROC: 0.943739\n",
      "Epoch 4/10\n",
      "127656/127656 [==============================] - 222s 2ms/step - loss: 0.0440 - acc: 0.9857 - val_loss: 0.0701 - val_acc: 0.9796\n",
      "val AUROC: 0.949563\n",
      "Epoch 5/10\n",
      "127656/127656 [==============================] - 201s 2ms/step - loss: 0.0376 - acc: 0.9879 - val_loss: 0.0726 - val_acc: 0.9798\n",
      "val AUROC: 0.950013\n",
      "Epoch 6/10\n",
      "127656/127656 [==============================] - 193s 2ms/step - loss: 0.0328 - acc: 0.9896 - val_loss: 0.0738 - val_acc: 0.9798\n",
      "val AUROC: 0.951479\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "def create_count_vector_nn_model():\n",
    "    model = Sequential()\n",
    "    # first and only hidden layer with 128 units\n",
    "    model.add(Dense(128, activation='relu', input_shape=(max_features,)))\n",
    "\n",
    "    # since we are classifying each label separately, we use a sigmoid function for the output layer and \n",
    "    # binary_crossentropy as the loss function\n",
    "    model.add(Dense(6, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_count_vector_nn = create_count_vector_nn_model()\n",
    "\n",
    "# add early stopping which checks validation loss to avoid overfitting. \n",
    "# if the validation loss does not decrease by more than 0.0001 for more than 2 epochs, training stops.\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose=1)\n",
    "\n",
    "auroc = AUROC(validation_data=(x_validation, y_validation))\n",
    "\n",
    "hist_count_vector_nn = model_count_vector_nn.fit(x_train, y_train, batch_size=500, epochs=10, \n",
    "                                                 validation_data=(x_validation, y_validation), \n",
    "                                                 callbacks=[early_stopping, auroc])\n",
    "\n",
    "# save model in case it's needed later\n",
    "model_count_vector_nn.save('models/history/count_vector_nn.h5')\n",
    "\n",
    "# save model history in case it's needed later\n",
    "with open('models/history/count_vector_nn_hist','wb') as f:\n",
    "    pkl.dump(hist_count_vector_nn.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the validation loss and training loss logged by the model seems to indicate that there is no overfitting.\n",
    "\n",
    "This model seems to be providing a good result for an intial attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - NN Using Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/10\n",
      "127656/127656 [==============================] - 21s 163us/step - loss: 0.1324 - val_loss: 0.0694\n",
      "val AUROC: 0.956141\n",
      "Epoch 2/10\n",
      "127656/127656 [==============================] - 12s 97us/step - loss: 0.0583 - val_loss: 0.0606\n",
      "val AUROC: 0.962127\n",
      "Epoch 3/10\n",
      "127656/127656 [==============================] - 13s 99us/step - loss: 0.0503 - val_loss: 0.0599\n",
      "val AUROC: 0.962542\n",
      "Epoch 4/10\n",
      "127656/127656 [==============================] - 13s 105us/step - loss: 0.0459 - val_loss: 0.0598\n",
      "val AUROC: 0.961091\n",
      "Epoch 5/10\n",
      "127656/127656 [==============================] - 13s 103us/step - loss: 0.0423 - val_loss: 0.0613\n",
      "val AUROC: 0.959191\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "def create_embedding_nn_model():\n",
    "    embedding_size = 16\n",
    "    model_embedding_nn = Sequential()\n",
    "\n",
    "    # Embedding layer to learn word embeddings. Embedding size chosen is 8\n",
    "    model_embedding_nn.add(Embedding(max_features, embedding_size, input_length=max_len))\n",
    "\n",
    "    # Flatten the output of the embedding layer so that it can be given as an input to a hidden layer\n",
    "    model_embedding_nn.add(Flatten())\n",
    "\n",
    "    # Single hidden layer with 64 hidden units\n",
    "    model_embedding_nn.add(Dense(64, activation='relu'))\n",
    "    model_embedding_nn.add(Dense(6, activation='sigmoid'))\n",
    "    model_embedding_nn.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model_embedding_nn\n",
    "\n",
    "model_embedding_nn = create_embedding_nn_model()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose=1)\n",
    "auroc = AUROC(validation_data=(x_validation_sequences_padded, y_validation))\n",
    "\n",
    "# Fit model using early stopping\n",
    "hist_embedding_nn = model_embedding_nn.fit(x_train_sequences_padded, y_train, batch_size=500, epochs=10, \n",
    "                                           validation_data=(x_validation_sequences_padded, y_validation), \n",
    "                                           callbacks=[early_stopping, auroc])\n",
    "\n",
    "model_embedding_nn.save('models/embedding_nn.h5')\n",
    "\n",
    "with open('models/history/embedding_nn_hist','wb') as f:\n",
    "    pkl.dump(hist_embedding_nn.history, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model too has a similar performance as that of the baseline model. However, this has a better AUROC and validation loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - NN Using a Pre-trained Embedding\n",
    "\n",
    "The pre-trained model selected is GloVe. The model pre-trained on Twitter data is selected in the hopes that it reflects online user behaviour and generalizes well for our use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "[\"don't\", \"i'm\", \"it's\", \"i've\", \"you're\", \"doesn't\", \"that's\", \"i'll\", \"didn't\", \"can't\", \"isn't\", \"i'd\", \"there's\", 'contribs', \"wikipedia's\", \"you've\", \"wasn't\", \"won't\", \"he's\", 'wikiproject', 'npov', \"haven't\", \"article's\", \"what's\", \"wouldn't\", \"aren't\", \"shouldn't\", \"let's\", \"they're\", \"you'll\", 'infobox', \"we're\", \"''''''\", \"you'd\", 'barnstar', 'unsourced', 'wikipedians', \"couldn't\", 'fucksex', 'sockpuppet', 'disambiguation', 'fffa', \"here's\", 'buttsecks', \"subject's\", 'arbcom', 'verifiability', 'userpage', \"people's\", 'philippineslong', '—preceding', 'mothjer', \"hasn't\", 'talkpage', 'offfuck', 'gfdl', 'oldid', 'sexsex', 'deneid', \"we'll\", \"'fuck\", 'pagedelete', 'yourselfgo', 'notrhbysouthbanof', \"'image'\", \"weren't\", \"'''\", \"we've\", 'sockpuppetry', 'cellpadding', \"she's\", 'bunksteve', 'marcolfuck', 'unconstructive', 'ytmnd', 'deletions', \"who's\", 'securityfuck', \"user's\", 'mainpagebg', 'adminship', 'youbollocks', \"hadn't\", \"they've\", 'don’t', \"''''\", '\\u200e', 'conformance', \"one's\", \"someone's\", 'checkuser', 'ffffff', 'copyvio', 'sockpuppets', 'ullmann', \"editor's\", \"administrators'\", \"world's\", \"person's\", 'reversions', \"contributors'\", \"ain't\", 'unreferenced', 'sitush', \"it'll\", 'incivility', \"website's\", \"page's\", 'aidsaids', 'cellspacing', 'userbox', \"'the\", 'it’s', 'bitchmattythewhite', 'wikilove', 'userspace', \"wiki's\", 'infoboxes', 'turkic', \"we'd\", \"else's\", 'userboxes', 'nhrhs', 'subsection', 'subpage', \"'u\", 'cheesei', 'i’m', \"others'\", \"they'll\", \"jones'\", 'chocobos', \"today's\", 'macedonians', \"it'd\", 'cuntliz', 'uncited', 'fatuorum', 'supertr', 'fffff', 'uuuuuu', \"ip's\", 'lightgrey', 'sysop', 'cccccc', 'wikinews', \"they'd\", 'tabtab', 'wikiprojects', \"he'll\", 'mainspace', \"file's\", 'rexcurry', 'gayfag', \"he'd\", \"women's\", 'cuntfranks', \"man's\", \"image's\", 'bishonen', \"god's\", 'concensus', 'wikipedias', 'transcluded', '“the', 'latinus', \"fuckin'\", \"men's\", \"other's\", 'unencyclopedic', \"everyone's\", 'jasenm', 'tendentious', \"anyone's\", 'khoikhoi', 'misterwiki', 'enyclopedia', 'malleus', 'slimvirgin', '—the', 'bongwarriorcongratualtions', 'unverifiable', 'restatement', \"editors'\", 'njgw', 'antivman', 'awardhttp', 'encyclopaedic', 'mediawiki', 'jforget', 'neutrally', 'wikibreak', \"author's\", 'wikiquette', 'hawkinghttp', 'copyedit', 'incivil', 'elonka', 'valign', 'sannse', 'lolooolbootstoots', 'wiktionary', 'billj', 'afds', 'blofeld', 'disambig', \"where's\", \"obama's\", \"mother's\", 'doesn’t', 'rajputs', 'ruleset', 'copyediting', 'failepic', 'fuckbags', 'subpages', \"users'\", 'wikilinks', 'rationales', \"guy's\", 'drmies', 'nableezy', 'interwiki', \"workers'\", \"how's\", 'chzz', \"school's\", 'wikilink', 'couriano', \"breast's\", 'connolley', 'jayjg', 'jéské', \"''''''''''\", 'hellor', \"contributor's\", \"admin's\", 'semite', 'it´s', \"father's\", \"children's\", 'uncontroversial', 'carrots→', 'betacommand', 'userpages', 'rowspan', 'nfcc', \"john's\", 'technocracy', 'gamergate', 'neologism', 'nrhp', 'syriac', 'slavs', 'redlinks', 'deletionist', 'wikipeida', \"king's\", 'encylopedia', 'didn’t', 'isn’t', 'barnstars', 'shankbone', 'bauder', \"—''''''\", 'curps', 'autoblock', 'ryulong', \"belle's\", 'wqa', \"creator's\", \"would've\", \"'i\", 'unsalvageably', 'wikify', 'orangemike', 'sharealike', 'hatnote', \"administrator's\", 'sidaway', 'farmbrough', 'wikipedia’s', 'urantia', 'binksternet', 'i’ve', 'talk•', \"company's\", 'nccc', 'rfar', 'onepage', 'don´t', \"band's\", 'transliteration', 'gabsadds', 'ossetia', \"'a\", 'alexandrovich', 'ummmmmmm', 'wikisource', 'that’s', 'can’t', \"jimbo's\", 'redlink', \"project's\", 'subsections', \"artist's\", 'joshuaz', 'enigmaman', 'colspan', \"israel's\", 'tangential', 'youcaltlas', 'dougweller', 'talkpages', 'medrs', 'vladimirovich', 'reinsert', 'roering', \"wp's\", 'arbitrators', 'anarcho', 'bwilkins', 'reflist', \"government's\", 'wikistalking', 'jehochman', 'unambiguously', 'you’re', 'undeletion', '“i', \"category's\", \"week's\", 'semites', \"djathinkimacowboy's\", 'wolfowitz', 'genseiryu', 'illyrians', 'hesperian', \"paul's\", \"that'll\", \"that'd\", \"hitler's\", \"year's\", 'fancruft', 'wikified', 'highking', 'jealouslyfavonian', 'blps', 'substantiated', 'copyvios', 'orlady', 'diacritics', 'andemu', 'neiln', 'toddst', 'sysops', \"group's\", 'soapboxing', \"country's\", 'alexikoua', \"should've\", \"queen's\", 'shoit', 'uncyclopedia', 'pmanderson', 'dαlus', 'azeris', 'montenegrin', 'swatjester', \"film's\", 'malke', \"site's\", 'ramdasia', 'roskam', 'iranica', 'cluebot', 'chalukya', 'gwernol', \"peoples'\", \"'''rolls'''\", 'meatpuppet', 'tajiks', 'disambiguate', 'kimes', 'allmusic', 'cohanim', 'yehovah', 'viii', 'monobook', 'wikpedia', 'dickbutt', 'berlet', 'bosniaks', 'wikiquote', 'conservapedia', \"earth's\", 'shtml', \"andy's\", \"jehovah's\", 'autoconfirmed']\n",
      "Train on 114890 samples, validate on 12766 samples\n",
      "Epoch 1/10\n",
      "114890/114890 [==============================] - 291s 3ms/step - loss: 0.0772 - val_loss: 0.0592\n",
      "val AUROC: 0.964022\n",
      "Epoch 2/10\n",
      "114890/114890 [==============================] - 275s 2ms/step - loss: 0.0455 - val_loss: 0.0581\n",
      "val AUROC: 0.967281\n",
      "Epoch 3/10\n",
      "114890/114890 [==============================] - 270s 2ms/step - loss: 0.0348 - val_loss: 0.0627\n",
      "val AUROC: 0.967523\n",
      "Epoch 4/10\n",
      "114890/114890 [==============================] - 402s 3ms/step - loss: 0.0269 - val_loss: 0.0669\n",
      "val AUROC: 0.964416\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "# the selected GloVe model is the one with dimension = 100\n",
    "transfer_embedding_size = 100\n",
    "\n",
    "# create glove embeddings of our vocabulary\n",
    "def create_embedding_matrix():\n",
    "    glove_embeddings_index = dict()\n",
    "    \n",
    "    # create the glove embeddings index\n",
    "    with open('data/glove.twitter.27B.100d.txt', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            glove_embeddings_index[word] = coefs\n",
    "\n",
    "    # glove embeddings of our vocabulary\n",
    "    embedding_matrix = np.zeros((len(tokenizer.word_index)+1, transfer_embedding_size))\n",
    "\n",
    "    # words in our vocabulary that do not have a corresponding glove embedding\n",
    "    words_with_no_embedding = []\n",
    "\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = glove_embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        elif i < 10000:\n",
    "            words_with_no_embedding.append(word)\n",
    "        \n",
    "    print (len(words_with_no_embedding))\n",
    "    print (words_with_no_embedding)\n",
    "    \n",
    "    # save the embedding_matrix for later use\n",
    "    with open(\"data/glove_embedding_matrix.pickle\", \"wb\") as f:\n",
    "        pkl.dump(embedding_matrix, f)\n",
    "        \n",
    "    return embedding_matrix\n",
    "        \n",
    "\n",
    "def load_embedding_matrix():\n",
    "    embedding_matrix = None\n",
    "    with open(\"data/glove_embedding_matrix.pickle\", \"rb\") as f:\n",
    "        embedding_matrix = pkl.load(f)\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "def create_glove_nn_model():\n",
    "    model_glove_nn = Sequential()\n",
    "\n",
    "    # embedding_matrix = create_embedding_matrix()\n",
    "    embedding_matrix = load_embedding_matrix()\n",
    "    \n",
    "    # Embedding layer with weights initialized from glove_embedding_matrix.\n",
    "    # The weights of the embedding layer will be adjusted during training, since trainable is not set to False.\n",
    "    # By trial and error, it was found that training the embedding layer yielded better results.\n",
    "    model_glove_nn.add(Embedding(len(tokenizer.word_index)+1, transfer_embedding_size, input_length=max_len, \n",
    "                             weights=[embedding_matrix]))\n",
    "    # flatten the word embeddings, so that it can be fed to a Dense layer.\n",
    "    model_glove_nn.add(Flatten())\n",
    "    model_glove_nn.add(Dense(256, activation='relu'))\n",
    "    model_glove_nn.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "    model_glove_nn.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model_glove_nn\n",
    "\n",
    "\n",
    "model_glove_nn = create_glove_nn_model()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose=1)\n",
    "auroc = AUROC(validation_data=(x_validation_sequences_padded, y_validation))\n",
    "\n",
    "hist_glove_nn = model_glove_nn.fit(x_train_sequences_padded, y_train, batch_size=500, epochs=10,\n",
    "                                  validation_data=(x_validation_sequences_padded, y_validation),\n",
    "                                  callbacks=[early_stopping, auroc])\n",
    "\n",
    "model_glove_nn.save('models/glove_nn.h5')\n",
    "with open('models/history/glove_nn_hist', 'wb') as f:\n",
    "    pkl.dump(hist_glove_nn.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 400 words in our vocabulary that do not have a corresponding embedding in glove. Most of them seems to be ones that can be safely ignored. \n",
    "\n",
    "The performance of this model is better than that of the model with a learned embedding. However, an embedding layer initialized with glove vectors but not trainable had yielded worse results. (Those results are not shown in this notebook). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 - RNN Using Embedding\n",
    "\n",
    "Since the glove model yielded better results, trying an RNN with LSTM cell that uses the same trainable embedding. Keeping track of the words in the comments in memory might prove to be useful to understand the comment better. This is the intuition behind using an RNN. Also, since words early on in the comment could be more useful, we are using an LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114890 samples, validate on 12766 samples\n",
      "Epoch 1/20\n",
      "114890/114890 [==============================] - 1055s 9ms/step - loss: 0.1318 - val_loss: 0.0546\n",
      "val AUROC: 0.970560\n",
      "Epoch 2/20\n",
      "114890/114890 [==============================] - 1117s 10ms/step - loss: 0.0552 - val_loss: 0.0494\n",
      "val AUROC: 0.974625\n",
      "Epoch 3/20\n",
      "114890/114890 [==============================] - 1160s 10ms/step - loss: 0.0489 - val_loss: 0.0480\n",
      "val AUROC: 0.977281\n",
      "Epoch 4/20\n",
      "114890/114890 [==============================] - 1231s 11ms/step - loss: 0.0453 - val_loss: 0.0477\n",
      "val AUROC: 0.978690\n",
      "Epoch 5/20\n",
      "114890/114890 [==============================] - 1325s 12ms/step - loss: 0.0426 - val_loss: 0.0477\n",
      "val AUROC: 0.979430\n",
      "Epoch 6/20\n",
      "114890/114890 [==============================] - 1282s 11ms/step - loss: 0.0401 - val_loss: 0.0496\n",
      "val AUROC: 0.979345\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "def create_rnn_model():\n",
    "    embedding_size = 16\n",
    "    model_embedding_rn = Sequential()\n",
    "    \n",
    "    # load GloVe embedding matrix used in previous model\n",
    "    embedding_matrix = load_embedding_matrix()\n",
    "    \n",
    "    # trainable embedding layer initialized using the embedding matrix from above\n",
    "    model_embedding_rn.add(Embedding(len(tokenizer.word_index)+1, transfer_embedding_size, input_length=max_len, \n",
    "                             weights=[embedding_matrix]))\n",
    "\n",
    "    # LSTM layer with dropout - since LSTMs are prone to overfitting\n",
    "    model_embedding_rn.add(LSTM(100, dropout=0.1, recurrent_dropout=0.1))\n",
    "    model_embedding_rn.add(Dense(32, activation='relu'))\n",
    "    # more dropout regularization\n",
    "    model_embedding_rn.add(Dropout(0.1))\n",
    "    model_embedding_rn.add(Dense(6, activation='sigmoid'))\n",
    "    model_embedding_rn.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model_embedding_rn\n",
    "\n",
    "\n",
    "model_embedding_rn = create_rnn_model()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose=1)\n",
    "auroc = AUROC(validation_data=(x_validation_sequences_padded, y_validation))\n",
    "\n",
    "hist_embedding_rn = model_embedding_rn.fit(x_train_sequences_padded, y_train, batch_size=500, epochs=20, \n",
    "                                           validation_data=(x_validation_sequences_padded, y_validation), \n",
    "                                           callbacks=[early_stopping, auroc])\n",
    "\n",
    "model_embedding_rn.save('models/embedding_rn.h5')\n",
    "\n",
    "with open('models/history/embedding_rn_hist','wb') as f:\n",
    "    pkl.dump(hist_embedding_rn.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the validation loss and the validation auroc score, this seems to be the better model. However, the training time for the model to converge is higher compared to the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best-performing model\n",
    "from keras.models import load_model\n",
    "def load_saved_rnn_model():\n",
    "    return load_model('models/embedding_rn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Test Data using the Selected Model\n",
    "\n",
    "Since the RNN has the best performance in terms of validation loss and validation auroc score, we select that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_saved_rnn_model()\n",
    "\n",
    "# predict on held-out test data\n",
    "y_pred = model.predict(x_test_sequences_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Result Analysis\n",
    "Analyze AUROC scores and confusion matrix to get a better idea of the results, since there is class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUROC Score: 0.9800690380177524\n",
      "toxic : 0.9734392480335463\n",
      "severe_toxic : 0.9878210443845843\n",
      "obscene : 0.9886028243622969\n",
      "threat : 0.9727391591260901\n",
      "insult : 0.9806614957212978\n",
      "identity_hate : 0.977150456478699\n"
     ]
    }
   ],
   "source": [
    "# analyze mean auroc score and auroc score for each label\n",
    "auroc_score = roc_auc_score(y_test, y_pred)\n",
    "print ('Mean AUROC Score:', auroc_score)\n",
    "\n",
    "for i in range(0, 6):\n",
    "    print (dependent_vars[i], ':', roc_auc_score(y_test[:, i], y_pred[:, i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean AUROC score of the validation data has translated well to the test data. The model seems to predicting 'obscene' labels well. On the other hand, 'threat' and 'identity_hate' labels seem to have taken a hit. This could be due to the label imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make absolute predictions using a threshold of 0.5\n",
    "threshold = 0.5\n",
    "y_pred[y_pred >= threshold] = 1\n",
    "y_pred[y_pred < threshold] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "TN,      FP,    FN,    TP\n",
      "[28526   272   944  2173]\n",
      "\n",
      "\n",
      "severe_toxic\n",
      "TN,      FP,    FN,    TP\n",
      "[31495    60   285    75]\n",
      "\n",
      "\n",
      "obscene\n",
      "TN,      FP,    FN,    TP\n",
      "[29956   252   340  1367]\n",
      "\n",
      "\n",
      "threat\n",
      "TN,      FP,    FN,    TP\n",
      "[31819     4    89     3]\n",
      "\n",
      "\n",
      "insult\n",
      "TN,      FP,    FN,    TP\n",
      "[29975   333   534  1073]\n",
      "\n",
      "\n",
      "identity_hate\n",
      "TN,      FP,    FN,    TP\n",
      "[31612    34   204    65]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check confusion matrix for each label\n",
    "for i in range(0, 6):\n",
    "    print (dependent_vars[i])\n",
    "    print ('TN,      FP,    FN,    TP')\n",
    "    print (confusion_matrix(y_test[:, i], y_pred[:, i]).ravel())\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis above seems to be right. The model especially seems to be struggling with the threat label. It is reluctant to label a comment as a threat - only 3 TPs out of ~32K data points when in fact there were 92 true labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Misclassified Threat Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "print (\"Comments that are TP threats: \")\n",
    "print (test['comment_text'].loc[np.logical_and(y_pred[:, 3] == 1, y_test[:, 3] == 1)])\n",
    "\n",
    "print (\"\\n\\n\\nComments that are FN threats: \")\n",
    "print (test['comment_text'].loc[np.logical_and(y_pred[:, 3] == 0, y_test[:, 3] == 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the examples above, the model seems to need strong evidence without too much dilution of features like 'kill' and 'die' by other words, to label a comment as a threat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements\n",
    "\n",
    "##### Code Improvements:\n",
    "1. Use scikit-learn Pipeline to modularize the code more.\n",
    "2. Use GridSearchCV for better tuning of hyperparameters\n",
    "\n",
    "##### Model Improvements:\n",
    "1. Set the 'class_weights' parameter in the fit function to inverse class frequencies as mentioned [here](https://keras.io/models/sequential/#fit).\n",
    "2. Try an ensemble of models with each model focusing on one label. Each model can then try to optimize an f1_score for the label it focuses on.\n",
    "3. Pseudo-labeling could be tried after the model reaches a satisfactory performance on labels that are causing issues.\n",
    "4. Use more efficient preprocessing:\n",
    "   a) Remove spelling mistakes by using edit distances. A GloVe or similar model could be used to correct these mistakes.\n",
    "   b) Try a bigger vocabulary size\n",
    "   c) Lemmatizing\n",
    "5. Choose better thresholds for the different labels for prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
